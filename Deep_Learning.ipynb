{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Deep Learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets      import mnist # Números\n",
    "from keras.models        import Sequential\n",
    "from keras.layers        import Dense, Dropout\n",
    "from keras.utils         import np_utils\n",
    "from sklearn.metrics     import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Obtenção dos dados e divisão automática entre treinamento e teste**\n",
    "### - mnist faz a divisão automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_treinamento, y_treinamento), (X_teste, y_teste) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOtUlEQVR4nO3df6hc9ZnH8c8nscElSWNi0A2prm1VsrvB3i4hLFuJWbTiipAUbKmLkrBdr+xW3cKKK65SYWksZtt1BREiapPSqsUkKN1KK0Gi8Y9glERjjRpDbKPhXtSiZiG6Mc/+MZNyjTPfc51fZ26e9wsuM3OeO+c8Tvzcc2a+58zXESEAJ75pdTcAYDAIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwo6WbM+zvdn2/9p+w/bf190TunNS3Q1gaN0t6SNJp0sakfQ/tndFxEu1doWOmTPocDzbMyX9QdLiiHi1ueynkt6MiJtqbQ4d4zAerZwr6eNjQW/aJekva+oHPUDY0cosSe8dt+w9SbNr6AU9QtjRyiFJnz9u2eclfVBDL+gRwo5WXpV0ku1zJiz7iiQ+nJvC+IAOLdl+SFJI+kc1Po3/laS/4dP4qYs9O9r5Z0l/Imlc0oOS/omgT23s2YEk2LMDSRB2IAnCDiRB2IEkBnohjG0+DQT6LCLcanlXe3bbl9h+xfZe21wgAQyxjofebE9X40yrr0s6IOlZSVdExG8Lz2HPDvRZP/bsSyXtjYh9EfGRpIckrehifQD6qJuwL5T0+wmPDzSXfYLtUds7bO/oYlsAutTNB3StDhU+dZgeEeskrZM4jAfq1M2e/YCkMyY8/oKkt7prB0C/dBP2ZyWdY/uLtmdI+rakx3rTFoBe6/gwPiKO2L5W0q8lTZd0P1dFAcNroFe98Z4d6L++nFQDYOog7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJgU7ZDEy0fPnyYn3Lli3F+rRp5X1Vaf1bt24tPvdExJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgFlf01erVq9vWrrvuuuJzzzvvvGK9apx9586dbWsbNmwoPvfuu+8u1o8cOVKs16ndLK5dnVRje7+kDyR9LOlIRCzpZn0A+qcXZ9D9bUS83YP1AOgj3rMDSXQb9pD0G9vP2R5t9Qu2R23vsL2jy20B6EK3h/Ffi4i3bJ8m6QnbeyLiqYm/EBHrJK2T+IAOqFNXe/aIeKt5Oy5ps6SlvWgKQO91HHbbM23PPnZf0sWSdveqMQC91fE4u+0vqbE3lxpvB34eET+oeA6H8SeY0ji6JF111VVta8uWLetq21Xj7EePHu143WeffXax/sYbb3S87n7r+Th7ROyT9JWOOwIwUAy9AUkQdiAJwg4kQdiBJAg7kARfJX2CO+WUU4r1kZGRYv2BBx4o1ufPn1+sn3zyycV6yZ49e4r1qqG3c889t+Ntn4jYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyznwBWrlzZtnb11VcXn3vxxRcX6/28jLTK2rVri/Wq3u69995etjPlsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ58CrrzyymJ9/fr1fdt21Vh2P9ktvxF50ursfRjxagBJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzD4GqcfQ777yzWC9dU3748OHic8fGxor12bNnF+vz5s0r1kuqenv//feL9Tlz5hTr/bzWfiqq3LPbvt/2uO3dE5bNs/2E7deat3P72yaAbk3mMP4nki45btlNkrZExDmStjQfAxhilWGPiKckvXvc4hWSjp2juV7Syt62BaDXOn3PfnpEHJSkiDho+7R2v2h7VNJoh9sB0CN9/4AuItZJWidJtqPf2wPQWqdDb2O2F0hS83a8dy0B6IdOw/6YpFXN+6skPdqbdgD0S+VhvO0HJS2XNN/2AUnfl/RDSb+w/R1Jv5P0zX42OdWVvtddqr4evZvx4u3btxfrF110UbG+evXqYr2b72a/+eabi/XNmzcX61W94ZMqwx4RV7QpXdjjXgD0EafLAkkQdiAJwg4kQdiBJAg7kASXuPZA1RBQ1SWqVaouBS0Nr11//fVdbbvKrl27ivXSsOI999zT1bYfeeSRYr00XfXSpUu72vZUxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0Hbr311mJ95syZXa1/zZo1xfrtt9/e1fpLtm3bVqw//vjjxXrVV1V349ChQ8X6hx9+2LdtT0Xs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZJ2lkZKRtrWpa42nTyn9Tp0+f3klLA7F37966W+iY7ba1qn+TE1G+/2IgKcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9qbFixcX6xs3bmxbmzt3bvG53Uy5jPZmzZpVrM+YMaNtLeO/SeWe3fb9tsdt756w7Dbbb9re2fy5tL9tAujWZA7jfyLpkhbL/ysiRpo/v+ptWwB6rTLsEfGUpHcH0AuAPurmA7prbb/QPMxv+6bV9qjtHbZ3dLEtAF3qNOz3SPqypBFJByX9qN0vRsS6iFgSEUs63BaAHugo7BExFhEfR8RRSfdKyjclJjDFdBR22wsmPPyGpN3tfhfAcKgcZ7f9oKTlkubbPiDp+5KW2x6RFJL2S7qmfy0Oxl133VWsn3nmmQPqBJN1+eWXF+sZ52AvqQx7RFzRYvF9fegFQB9xuiyQBGEHkiDsQBKEHUiCsANJcInrANx44411tzAlLVq0qFi/4447Ol73/v37i/XDhw93vO5hxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH0A3nnnnbpbGEpV4+iPPvposX7qqacW6+Pj421rVZfHjo2NFetTEXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCETG4jdmD29hn9OSTTxbry5Yt69u2p0+f3rd191vVtMkbNmxoW1uxYkVX2963b1+xftlll7WtvfLKK11te5hFhFstZ88OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lUjrPbPkPSBkl/KumopHUR8d+250l6WNJZakzb/K2I+EPFuoZ2nP3CCy8s1h9++OG2tTlz5nS17W3bthXrVf9Gpeu+q8aTq77T3m45ZPtHM2bMKNZL0yZXfTf7mjVrivVNmzYV6yfyWHpJN+PsRyT9a0T8uaS/lvRd238h6SZJWyLiHElbmo8BDKnKsEfEwYh4vnn/A0kvS1ooaYWk9c1fWy9pZZ96BNADn+k9u+2zJH1V0nZJp0fEQanxB0HSaT3vDkDPTPo76GzPkrRR0vci4v2q93ITnjcqabSz9gD0yqT27LY/p0bQfxYRxz4VGbO9oFlfIKnlt/tFxLqIWBIRS3rRMIDOVIbdjV34fZJejogfTyg9JmlV8/4qSeWvAgVQq8kMvZ0v6WlJL6ox9CZJN6vxvv0Xks6U9DtJ34yIdyvWNbRDb1UuuOCCtrWNGzcWn1s1NDdtWvlv7tGjR4v1fuq2t61bt7atlS5/nUwdrbUbeqt8zx4R2yS1e4NeHpwGMDQ4gw5IgrADSRB2IAnCDiRB2IEkCDuQBF8l3QMLFy4s1kdHy2cL33LLLcV6nePspWmPJenpp58u1q+55pq2tffee6+jnlDGV0kDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsw+BVatWFes33HBDsb5o0aK2tT179hSfu3bt2mL99ddfL9afeeaZYh2Dxzg7kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTBODtwgmGcHUiOsANJEHYgCcIOJEHYgSQIO5AEYQeSqAy77TNsP2n7Zdsv2f6X5vLbbL9pe2fz59L+twugU5Un1dheIGlBRDxve7ak5yStlPQtSYci4j8nvTFOqgH6rt1JNSdN4okHJR1s3v/A9suSylOgABg6n+k9u+2zJH1V0vbmomttv2D7fttz2zxn1PYO2zu6axVANyZ9brztWZK2SvpBRGyyfbqktyWFpP9Q41D/HyrWwWE80GftDuMnFXbbn5P0S0m/jogft6ifJemXEbG4Yj2EHeizji+EsW1J90l6eWLQmx/cHfMNSbu7bRJA/0zm0/jzJT0t6UVJx+YOvlnSFZJG1DiM3y/pmuaHeaV1sWcH+qyrw/heIexA/3E9O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IInKL5zssbclvTHh8fzmsmE0rL0Na18SvXWql739WbvCQK9n/9TG7R0RsaS2BgqGtbdh7Uuit04NqjcO44EkCDuQRN1hX1fz9kuGtbdh7Uuit04NpLda37MDGJy69+wABoSwA0nUEnbbl9h+xfZe2zfV0UM7tvfbfrE5DXWt89M159Abt717wrJ5tp+w/VrztuUcezX1NhTTeBemGa/1tat7+vOBv2e3PV3Sq5K+LumApGclXRERvx1oI23Y3i9pSUTUfgKG7WWSDknacGxqLdt3SHo3In7Y/EM5NyL+bUh6u02fcRrvPvXWbprx1arxtevl9OedqGPPvlTS3ojYFxEfSXpI0ooa+hh6EfGUpHePW7xC0vrm/fVq/M8ycG16GwoRcTAinm/e/0DSsWnGa33tCn0NRB1hXyjp9xMeH9Bwzfcekn5j+znbo3U308Lpx6bZat6eVnM/x6ucxnuQjptmfGheu06mP+9WHWFvNTXNMI3/fS0i/krS30n6bvNwFZNzj6QvqzEH4EFJP6qzmeY04xslfS8i3q+zl4la9DWQ162OsB+QdMaEx1+Q9FYNfbQUEW81b8clbVbjbccwGTs2g27zdrzmfv4oIsYi4uOIOCrpXtX42jWnGd8o6WcRsam5uPbXrlVfg3rd6gj7s5LOsf1F2zMkfVvSYzX08Sm2ZzY/OJHtmZIu1vBNRf2YpFXN+6skPVpjL58wLNN4t5tmXDW/drVPfx4RA/+RdKkan8i/Lunf6+ihTV9fkrSr+fNS3b1JelCNw7r/U+OI6DuSTpW0RdJrzdt5Q9TbT9WY2vsFNYK1oKbezlfjreELknY2fy6t+7Ur9DWQ143TZYEkOIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4f39unC/nD5RzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualização de imagens específicas\n",
    "plt.imshow(X_treinamento[21], cmap = 'gray')\n",
    "plt.title(y_treinamento[21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mudança de dimensão**\n",
    "### - Originalmente está em 28x28, mas precisamos 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(X_teste.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 222, 254, 254, 254,\n",
       "       254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170,  52,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67, 114,\n",
       "        72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254,\n",
       "       140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  17,  66,  14,  67,  67,  67,  59,  21,\n",
       "       236, 254, 106,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  83, 253, 209,  18,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 133, 254, 187,   5,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   9, 205, 248,  58,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 126, 254, 182,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  75, 251,\n",
       "       240,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,\n",
       "       221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         3, 203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  38, 254, 254,  77,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  31, 224, 254, 115,   1,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 133, 254, 254,  52,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  61, 242, 254, 254,  52,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254, 219,  40,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "        18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treinamento = X_treinamento.reshape((len(X_treinamento), np.prod(X_treinamento.shape[1:])))\n",
    "X_teste = X_teste.reshape((len(X_teste), np.prod(X_teste.shape[1:])))\n",
    "\n",
    "X_teste[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformação dos dados para float**\n",
    "### - Para podermos normalizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento = X_treinamento.astype('float32')\n",
    "X_teste = X_teste.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Normalização**\n",
    "### - 255 é o valor máximo de um pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento /= 255\n",
    "X_teste /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformação para o formato dummy**\n",
    "### - Temos 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento = np_utils.to_categorical(y_treinamento, 10)\n",
    "y_teste = np_utils.to_categorical(y_teste, 10)\n",
    "\n",
    "y_teste[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Estruturando a Rede neural**\n",
    "### - Estrutura da rede neural: 784 - 64 - 64 - 64 - 10\n",
    "### - Dropout é utilizado para zerar uma porcentagem dos neurônios, para evitar o overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "\n",
    "modelo.add(Dense(units = 64, activation = 'relu', input_dim = 784))\n",
    "modelo.add(Dropout(0.2)) # 20% dos dados da camada serão zerados\n",
    "\n",
    "modelo.add(Dense(units = 64, activation = 'relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "\n",
    "modelo.add(Dense(units = 64, activation = 'relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "\n",
    "# Camada de saída com 10 unidades, pois temos 10 opções de números, softmax para probabilidade de caracteres\n",
    "modelo.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Configuração da Rede Neural e Treinamento**\n",
    "### - Utilizamos a base de dados de validação\n",
    "### - Na variável histórico temos os históricos das execuções (erro e accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4507 - accuracy: 0.8631 - val_loss: 0.1670 - val_accuracy: 0.9494\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 2s 874us/step - loss: 0.2285 - accuracy: 0.9343 - val_loss: 0.1293 - val_accuracy: 0.9619\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 2s 853us/step - loss: 0.1900 - accuracy: 0.9451 - val_loss: 0.1084 - val_accuracy: 0.9679\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 2s 846us/step - loss: 0.1648 - accuracy: 0.9524 - val_loss: 0.0996 - val_accuracy: 0.9708\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 2s 880us/step - loss: 0.1509 - accuracy: 0.9554 - val_loss: 0.0974 - val_accuracy: 0.9697\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 2s 851us/step - loss: 0.1384 - accuracy: 0.9593 - val_loss: 0.0916 - val_accuracy: 0.9741\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 2s 861us/step - loss: 0.1334 - accuracy: 0.9606 - val_loss: 0.0936 - val_accuracy: 0.9725\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 2s 894us/step - loss: 0.1214 - accuracy: 0.9639 - val_loss: 0.0896 - val_accuracy: 0.9736\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 2s 868us/step - loss: 0.1167 - accuracy: 0.9653 - val_loss: 0.0903 - val_accuracy: 0.9747\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 2s 859us/step - loss: 0.1143 - accuracy: 0.9660 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 2s 907us/step - loss: 0.1089 - accuracy: 0.9673 - val_loss: 0.0891 - val_accuracy: 0.9735\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 2s 903us/step - loss: 0.1061 - accuracy: 0.9685 - val_loss: 0.0853 - val_accuracy: 0.9754\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1028 - accuracy: 0.9688 - val_loss: 0.0849 - val_accuracy: 0.9757\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0991 - accuracy: 0.9701 - val_loss: 0.0905 - val_accuracy: 0.9739\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.0960 - accuracy: 0.9700 - val_loss: 0.0895 - val_accuracy: 0.9742\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 2s 954us/step - loss: 0.0959 - accuracy: 0.9708 - val_loss: 0.0890 - val_accuracy: 0.9763\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 2s 880us/step - loss: 0.0956 - accuracy: 0.9711 - val_loss: 0.0847 - val_accuracy: 0.9764\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 2s 850us/step - loss: 0.0896 - accuracy: 0.9729 - val_loss: 0.0832 - val_accuracy: 0.9786\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 0.0865 - accuracy: 0.9738 - val_loss: 0.0855 - val_accuracy: 0.9770\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0888 - accuracy: 0.9726 - val_loss: 0.0849 - val_accuracy: 0.9766\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0867 - accuracy: 0.9725 - val_loss: 0.0875 - val_accuracy: 0.9766\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.0845 - accuracy: 0.9740 - val_loss: 0.0913 - val_accuracy: 0.9758\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 2s 883us/step - loss: 0.0847 - accuracy: 0.9746 - val_loss: 0.0837 - val_accuracy: 0.9776\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 2s 888us/step - loss: 0.0841 - accuracy: 0.9740 - val_loss: 0.0916 - val_accuracy: 0.9749\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 2s 852us/step - loss: 0.0784 - accuracy: 0.9763 - val_loss: 0.0823 - val_accuracy: 0.9774\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 2s 852us/step - loss: 0.0787 - accuracy: 0.9760 - val_loss: 0.0862 - val_accuracy: 0.9766\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 2s 871us/step - loss: 0.0769 - accuracy: 0.9759 - val_loss: 0.0976 - val_accuracy: 0.9742\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 2s 908us/step - loss: 0.0780 - accuracy: 0.9759 - val_loss: 0.0859 - val_accuracy: 0.9761\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 2s 868us/step - loss: 0.0786 - accuracy: 0.9755 - val_loss: 0.0912 - val_accuracy: 0.9755\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 2s 875us/step - loss: 0.0750 - accuracy: 0.9770 - val_loss: 0.0887 - val_accuracy: 0.9760\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 2s 851us/step - loss: 0.0729 - accuracy: 0.9776 - val_loss: 0.0863 - val_accuracy: 0.9779\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 2s 845us/step - loss: 0.0764 - accuracy: 0.9772 - val_loss: 0.0914 - val_accuracy: 0.9748\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 2s 881us/step - loss: 0.0747 - accuracy: 0.9767 - val_loss: 0.0936 - val_accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 2s 964us/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: 0.0976 - val_accuracy: 0.9760\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.0701 - accuracy: 0.9786 - val_loss: 0.0913 - val_accuracy: 0.9772\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0686 - accuracy: 0.9791 - val_loss: 0.0915 - val_accuracy: 0.9768\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.0696 - accuracy: 0.9785 - val_loss: 0.0891 - val_accuracy: 0.9771\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 2s 870us/step - loss: 0.0670 - accuracy: 0.9794 - val_loss: 0.0954 - val_accuracy: 0.9770\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 2s 923us/step - loss: 0.0702 - accuracy: 0.9784 - val_loss: 0.0933 - val_accuracy: 0.9761\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 2s 861us/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0933 - val_accuracy: 0.9771\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.97 - 2s 881us/step - loss: 0.0690 - accuracy: 0.9789 - val_loss: 0.0938 - val_accuracy: 0.9769\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 2s 882us/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 0.1022 - val_accuracy: 0.9770\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 0.0683 - accuracy: 0.9794 - val_loss: 0.0887 - val_accuracy: 0.9762\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 2s 855us/step - loss: 0.0661 - accuracy: 0.9797 - val_loss: 0.0852 - val_accuracy: 0.9795\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 2s 856us/step - loss: 0.0677 - accuracy: 0.9793 - val_loss: 0.0960 - val_accuracy: 0.9769\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 2s 845us/step - loss: 0.0636 - accuracy: 0.9801 - val_loss: 0.0914 - val_accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.0926 - val_accuracy: 0.9780\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 2s 876us/step - loss: 0.0636 - accuracy: 0.9804 - val_loss: 0.0889 - val_accuracy: 0.9769\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 2s 919us/step - loss: 0.0617 - accuracy: 0.9812 - val_loss: 0.0866 - val_accuracy: 0.9773\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 2s 895us/step - loss: 0.0622 - accuracy: 0.9808 - val_loss: 0.0952 - val_accuracy: 0.9772\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 2s 883us/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 0.0954 - val_accuracy: 0.9769\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 2s 884us/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.0960 - val_accuracy: 0.9760\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 2s 860us/step - loss: 0.0606 - accuracy: 0.9821 - val_loss: 0.1017 - val_accuracy: 0.9764\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 2s 890us/step - loss: 0.0608 - accuracy: 0.9808 - val_loss: 0.0997 - val_accuracy: 0.9767\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 2s 893us/step - loss: 0.0595 - accuracy: 0.9817 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 2s 882us/step - loss: 0.0609 - accuracy: 0.9816 - val_loss: 0.0917 - val_accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 2s 882us/step - loss: 0.0610 - accuracy: 0.9811 - val_loss: 0.0990 - val_accuracy: 0.9759\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 2s 848us/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.0933 - val_accuracy: 0.9776\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 2s 871us/step - loss: 0.0589 - accuracy: 0.9825 - val_loss: 0.1003 - val_accuracy: 0.9765\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 2s 945us/step - loss: 0.0618 - accuracy: 0.9813 - val_loss: 0.0946 - val_accuracy: 0.9779\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 2s 939us/step - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.0926 - val_accuracy: 0.9777\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 2s 852us/step - loss: 0.0599 - accuracy: 0.9817 - val_loss: 0.0987 - val_accuracy: 0.9764\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.0971 - val_accuracy: 0.9770\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 0.0572 - accuracy: 0.9828 - val_loss: 0.1001 - val_accuracy: 0.9765\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.0939 - val_accuracy: 0.9779\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 2s 937us/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 0.1003 - val_accuracy: 0.9769\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 0.0980 - val_accuracy: 0.9781\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 2s 996us/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.1016 - val_accuracy: 0.9770\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 2s 916us/step - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.0972 - val_accuracy: 0.9754\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 2s 909us/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 0.1028 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0573 - accuracy: 0.9826 - val_loss: 0.0964 - val_accuracy: 0.9776\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0537 - accuracy: 0.9834 - val_loss: 0.1051 - val_accuracy: 0.9771\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 2s 976us/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0976 - val_accuracy: 0.9772\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 2s 942us/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 0.0957 - val_accuracy: 0.9777\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 2s 897us/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 0.1073 - val_accuracy: 0.9771\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 2s 929us/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.1036 - val_accuracy: 0.9765\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 2s 926us/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.1033 - val_accuracy: 0.9744\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 2s 931us/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 0.1048 - val_accuracy: 0.9772\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 2s 898us/step - loss: 0.0541 - accuracy: 0.9836 - val_loss: 0.1079 - val_accuracy: 0.9762\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 2s 900us/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.1096 - val_accuracy: 0.9763\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 2s 896us/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 0.0968 - val_accuracy: 0.9777\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.1044 - val_accuracy: 0.9772\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 2s 881us/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.0980 - val_accuracy: 0.9775\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 0.0541 - accuracy: 0.9834 - val_loss: 0.0998 - val_accuracy: 0.9770\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 2s 862us/step - loss: 0.0502 - accuracy: 0.9843 - val_loss: 0.1002 - val_accuracy: 0.9777\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 2s 865us/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.0955 - val_accuracy: 0.9782\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 2s 891us/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.1037 - val_accuracy: 0.9784\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 2s 876us/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.0991 - val_accuracy: 0.9772\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1000 - val_accuracy: 0.9788\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 2s 876us/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.1033 - val_accuracy: 0.9769\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 2s 900us/step - loss: 0.0505 - accuracy: 0.9849 - val_loss: 0.0965 - val_accuracy: 0.9770\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 2s 888us/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.0935 - val_accuracy: 0.9788\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 2s 899us/step - loss: 0.0521 - accuracy: 0.9850 - val_loss: 0.0998 - val_accuracy: 0.9770\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 2s 933us/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.1049 - val_accuracy: 0.9783\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 2s 940us/step - loss: 0.0522 - accuracy: 0.9846 - val_loss: 0.1051 - val_accuracy: 0.9774\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 2s 935us/step - loss: 0.0537 - accuracy: 0.9839 - val_loss: 0.1015 - val_accuracy: 0.9773\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 2s 868us/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.1074 - val_accuracy: 0.9775\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 2s 871us/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.1097 - val_accuracy: 0.9756\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 2s 871us/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.1082 - val_accuracy: 0.9752\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 2s 904us/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.1113 - val_accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "modelo.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "historico = modelo.fit(X_treinamento, y_treinamento, epochs = 100,\n",
    "                       validation_data = (X_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualização dos `erros` e `accuracy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x225fb412970>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(historico.history.keys())\n",
    "\n",
    "# Evolução do erro, azul\n",
    "plt.plot(historico.history['val_loss'])\n",
    "\n",
    "# Performance da rede\n",
    "plt.plot(historico.history['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Obtenção das Previsões**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9992750e-20, 6.4440266e-11, 5.7798596e-11, ..., 1.0000000e+00,\n",
       "        1.8316039e-19, 9.5590014e-10],\n",
       "       [1.4150252e-18, 3.1007159e-09, 1.0000000e+00, ..., 3.0890440e-10,\n",
       "        3.2761371e-14, 1.6019183e-17],\n",
       "       [9.0322206e-22, 1.0000000e+00, 5.1827327e-11, ..., 3.5610077e-09,\n",
       "        7.1719172e-11, 4.7362368e-18],\n",
       "       ...,\n",
       "       [1.8107840e-18, 2.1355329e-12, 8.1310958e-11, ..., 1.6223357e-09,\n",
       "        7.7843813e-13, 4.5366100e-08],\n",
       "       [5.9708489e-28, 3.6513263e-21, 1.2953418e-21, ..., 7.4128824e-23,\n",
       "        9.5933678e-19, 1.1857248e-20],\n",
       "       [3.4268002e-14, 3.2749544e-19, 1.9518199e-15, ..., 7.1929674e-20,\n",
       "        2.7922686e-17, 2.2472418e-23]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes = modelo.predict(X_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Matriz de Confusão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 969,    1,    1,    2,    0,    2,    3,    1,    1,    0],\n",
       "       [   0, 1123,    3,    1,    0,    1,    1,    1,    5,    0],\n",
       "       [   4,    1, 1013,    4,    2,    0,    1,    4,    3,    0],\n",
       "       [   3,    0,    5,  981,    0,   10,    0,    4,    1,    6],\n",
       "       [   1,    0,    4,    0,  954,    0,    5,    0,    1,   17],\n",
       "       [   3,    1,    0,    5,    1,  862,   11,    1,    5,    3],\n",
       "       [   8,    2,    0,    1,    3,    6,  937,    0,    1,    0],\n",
       "       [   0,    3,    8,    4,    2,    0,    0, 1006,    0,    5],\n",
       "       [   7,    2,    5,    2,    7,    6,    0,    5,  930,   10],\n",
       "       [   2,    4,    0,    6,    6,    7,    0,    2,    2,  980]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste_matriz = [np.argmax(t) for t in y_teste]\n",
    "y_previsoes_matriz = [np.argmax(t) for t in previsoes]\n",
    "\n",
    "confusao = confusion_matrix(y_teste_matriz, y_previsoes_matriz)\n",
    "confusao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testando modelo em produção**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previsão com um novo registro, convertendo o array para o formato de matriz\n",
    "# Número 4\n",
    "y_treinamento[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passo a mesma posição para o modelo prever\n",
    "novo = X_treinamento[20]\n",
    "\n",
    "# De matriz para vetor\n",
    "novo = np.expand_dims(novo, axis = 0) # Expande o tamanho do array\n",
    "\n",
    "# Previsao\n",
    "pred = modelo.predict(novo)\n",
    "\n",
    "# Maior valor\n",
    "pred = [np.argmax(pred) for t in pred]\n",
    "pred\n",
    "\n",
    "# PREDIÇÃO CORRETA"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "343f115f40a8053497179efaaabbcede37074ddc2d78a1917bbcb3055274ce2f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
