{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Massato01/Number-Identification-with-Neual-Network/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQXY6VCxSZiT"
      },
      "source": [
        "# ***Number Identification with Neural Network***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "va9kku7xSZiW"
      },
      "outputs": [],
      "source": [
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets      import mnist # Numbers form 0 to 9\n",
        "from keras.models        import Sequential\n",
        "from keras.layers        import Dense, Dropout\n",
        "from keras.utils         import np_utils\n",
        "from sklearn.metrics     import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "aQ5zjxO5SZiY"
      },
      "outputs": [],
      "source": [
        "# mnist automaticly divides the data between TRAIN and TEST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hw7tRfjTSZiY",
        "outputId": "46996b12-46e1-4f9b-e318-4330012f2cd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualizing specific images\n",
        "plt.imshow(X_train[21], cmap = 'gray')\n",
        "plt.title(y_train[21])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832GpHVFSZiZ",
        "outputId": "030f156b-cd78-476c-844d-4a7d889d2797"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 222, 254, 254, 254,\n",
              "       254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170,  52,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67, 114,\n",
              "        72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254,\n",
              "       140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  17,  66,  14,  67,  67,  67,  59,  21,\n",
              "       236, 254, 106,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,  83, 253, 209,  18,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 133, 254, 187,   5,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   9, 205, 248,  58,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 126, 254, 182,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  75, 251,\n",
              "       240,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,\n",
              "       221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         3, 203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  38, 254, 254,  77,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  31, 224, 254, 115,   1,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 133, 254, 254,  52,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,  61, 242, 254, 254,  52,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254, 219,  40,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "        18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Changing the dimension --> originaly was 28x28, we need 784\n",
        "np.prod(X_test.shape[1:])\n",
        "\n",
        "# Formating the X train and Test data\n",
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
        "\n",
        "X_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-ExH7YUfSZia"
      },
      "outputs": [],
      "source": [
        "# Normalizing the data transforming into float type and dividing by 225\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# 255 is the max value for a pixel\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6jSGJ30SZib",
        "outputId": "e5bcd8d7-6387-4e97-9e5e-c503e45ef65d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Transforming classes into DUMMY format (True = 1, False = 0)\n",
        "# 10 classes -> numbers from 0 to 9\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "y_test[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Structuring the Neural Network***"
      ],
      "metadata": {
        "id": "kBrM_kKxjr8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jVYK0D2WSZic"
      },
      "outputs": [],
      "source": [
        "# - Neural Network structure: 784 - 64 - 64 - 64 - 10\n",
        "# - Dropout it's used to avoid overffiting\n",
        "neural_network = Sequential()\n",
        "\n",
        "neural_network.add(Dense(units = 64, activation = 'relu', input_dim = 784))\n",
        "neural_network.add(Dropout(0.2)) # 20% dos dados da camada serão zerados\n",
        "\n",
        "neural_network.add(Dense(units = 64, activation = 'relu'))\n",
        "neural_network.add(Dropout(0.2))\n",
        "\n",
        "neural_network.add(Dense(units = 64, activation = 'relu'))\n",
        "neural_network.add(Dropout(0.2))\n",
        "\n",
        "# Camada de saída com 10 unidades, pois temos 10 opções de números, softmax para probabilidade de caracteres\n",
        "neural_network.add(Dense(units = 10, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqv_lhC-SZic",
        "outputId": "c73dbcd1-3ecc-46df-8fde-badffaec98d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 64)                50240     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,210\n",
            "Trainable params: 59,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "neural_network.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Setting and Training the Neural Network***"
      ],
      "metadata": {
        "id": "DESW1sxJj2oc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZuihaZuSZic",
        "outputId": "27fb4d24-9bd1-4407-dfbb-76092b4e06e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4614 - accuracy: 0.8571 - val_loss: 0.1593 - val_accuracy: 0.9509\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2300 - accuracy: 0.9331 - val_loss: 0.1440 - val_accuracy: 0.9580\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1889 - accuracy: 0.9452 - val_loss: 0.1185 - val_accuracy: 0.9646\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1646 - accuracy: 0.9522 - val_loss: 0.1008 - val_accuracy: 0.9712\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1480 - accuracy: 0.9563 - val_loss: 0.0979 - val_accuracy: 0.9697\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1378 - accuracy: 0.9591 - val_loss: 0.0942 - val_accuracy: 0.9713\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1290 - accuracy: 0.9624 - val_loss: 0.0927 - val_accuracy: 0.9731\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1230 - accuracy: 0.9640 - val_loss: 0.0962 - val_accuracy: 0.9720\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1164 - accuracy: 0.9642 - val_loss: 0.0881 - val_accuracy: 0.9737\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1123 - accuracy: 0.9662 - val_loss: 0.0842 - val_accuracy: 0.9746\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1085 - accuracy: 0.9670 - val_loss: 0.0851 - val_accuracy: 0.9752\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1037 - accuracy: 0.9693 - val_loss: 0.0872 - val_accuracy: 0.9739\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9706 - val_loss: 0.0889 - val_accuracy: 0.9745\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0985 - accuracy: 0.9704 - val_loss: 0.0869 - val_accuracy: 0.9757\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0939 - accuracy: 0.9718 - val_loss: 0.0841 - val_accuracy: 0.9760\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0936 - accuracy: 0.9719 - val_loss: 0.0857 - val_accuracy: 0.9757\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9719 - val_loss: 0.0905 - val_accuracy: 0.9738\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0892 - accuracy: 0.9732 - val_loss: 0.0857 - val_accuracy: 0.9764\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0859 - accuracy: 0.9743 - val_loss: 0.0936 - val_accuracy: 0.9742\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0874 - accuracy: 0.9745 - val_loss: 0.0818 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0861 - accuracy: 0.9741 - val_loss: 0.0835 - val_accuracy: 0.9772\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0821 - accuracy: 0.9758 - val_loss: 0.0875 - val_accuracy: 0.9768\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0794 - accuracy: 0.9762 - val_loss: 0.0898 - val_accuracy: 0.9760\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0811 - accuracy: 0.9753 - val_loss: 0.0792 - val_accuracy: 0.9776\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9755 - val_loss: 0.0876 - val_accuracy: 0.9776\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0775 - accuracy: 0.9766 - val_loss: 0.0825 - val_accuracy: 0.9782\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9766 - val_loss: 0.0842 - val_accuracy: 0.9782\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0767 - accuracy: 0.9772 - val_loss: 0.0888 - val_accuracy: 0.9769\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0744 - accuracy: 0.9770 - val_loss: 0.0880 - val_accuracy: 0.9756\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0716 - accuracy: 0.9780 - val_loss: 0.0919 - val_accuracy: 0.9753\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0748 - accuracy: 0.9773 - val_loss: 0.0825 - val_accuracy: 0.9776\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0707 - accuracy: 0.9781 - val_loss: 0.0884 - val_accuracy: 0.9769\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0725 - accuracy: 0.9777 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0672 - accuracy: 0.9799 - val_loss: 0.0928 - val_accuracy: 0.9776\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0706 - accuracy: 0.9790 - val_loss: 0.0931 - val_accuracy: 0.9764\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0962 - val_accuracy: 0.9763\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0677 - accuracy: 0.9790 - val_loss: 0.0850 - val_accuracy: 0.9757\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0674 - accuracy: 0.9797 - val_loss: 0.0869 - val_accuracy: 0.9767\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0669 - accuracy: 0.9796 - val_loss: 0.0915 - val_accuracy: 0.9780\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0653 - accuracy: 0.9800 - val_loss: 0.0978 - val_accuracy: 0.9769\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0674 - accuracy: 0.9796 - val_loss: 0.0962 - val_accuracy: 0.9770\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0652 - accuracy: 0.9801 - val_loss: 0.0938 - val_accuracy: 0.9771\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.0953 - val_accuracy: 0.9768\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0634 - accuracy: 0.9811 - val_loss: 0.0956 - val_accuracy: 0.9771\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9803 - val_loss: 0.0907 - val_accuracy: 0.9767\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0610 - accuracy: 0.9813 - val_loss: 0.0945 - val_accuracy: 0.9772\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0639 - accuracy: 0.9809 - val_loss: 0.0963 - val_accuracy: 0.9765\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9780\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0973 - val_accuracy: 0.9769\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0583 - accuracy: 0.9822 - val_loss: 0.0939 - val_accuracy: 0.9772\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.1010 - val_accuracy: 0.9748\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 0.0976 - val_accuracy: 0.9767\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9814 - val_loss: 0.0931 - val_accuracy: 0.9755\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0587 - accuracy: 0.9824 - val_loss: 0.1000 - val_accuracy: 0.9756\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0591 - accuracy: 0.9822 - val_loss: 0.0968 - val_accuracy: 0.9772\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.0983 - val_accuracy: 0.9773\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0568 - accuracy: 0.9828 - val_loss: 0.1033 - val_accuracy: 0.9752\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0547 - accuracy: 0.9826 - val_loss: 0.1074 - val_accuracy: 0.9757\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.1011 - val_accuracy: 0.9770\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.0991 - val_accuracy: 0.9764\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0581 - accuracy: 0.9829 - val_loss: 0.0917 - val_accuracy: 0.9785\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0562 - accuracy: 0.9823 - val_loss: 0.0973 - val_accuracy: 0.9791\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.0951 - val_accuracy: 0.9773\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.0990 - val_accuracy: 0.9789\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0571 - accuracy: 0.9826 - val_loss: 0.0955 - val_accuracy: 0.9760\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0592 - accuracy: 0.9821 - val_loss: 0.0967 - val_accuracy: 0.9764\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.0978 - val_accuracy: 0.9773\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0560 - accuracy: 0.9828 - val_loss: 0.0985 - val_accuracy: 0.9770\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.1035 - val_accuracy: 0.9751\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.1007 - val_accuracy: 0.9771\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0539 - accuracy: 0.9834 - val_loss: 0.1030 - val_accuracy: 0.9773\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.1051 - val_accuracy: 0.9776\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0538 - accuracy: 0.9841 - val_loss: 0.1110 - val_accuracy: 0.9761\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.1081 - val_accuracy: 0.9770\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.1089 - val_accuracy: 0.9780\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 0.1143 - val_accuracy: 0.9763\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0543 - accuracy: 0.9836 - val_loss: 0.1084 - val_accuracy: 0.9782\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.1144 - val_accuracy: 0.9765\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.1097 - val_accuracy: 0.9764\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0538 - accuracy: 0.9844 - val_loss: 0.1065 - val_accuracy: 0.9773\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.1038 - val_accuracy: 0.9765\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0528 - accuracy: 0.9841 - val_loss: 0.1079 - val_accuracy: 0.9768\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.1000 - val_accuracy: 0.9779\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.1141 - val_accuracy: 0.9764\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0497 - accuracy: 0.9851 - val_loss: 0.1188 - val_accuracy: 0.9772\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1068 - val_accuracy: 0.9774\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.1150 - val_accuracy: 0.9779\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0510 - accuracy: 0.9847 - val_loss: 0.1163 - val_accuracy: 0.9757\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.1152 - val_accuracy: 0.9756\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0534 - accuracy: 0.9847 - val_loss: 0.1020 - val_accuracy: 0.9774\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0502 - accuracy: 0.9848 - val_loss: 0.1107 - val_accuracy: 0.9761\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0514 - accuracy: 0.9849 - val_loss: 0.1131 - val_accuracy: 0.9767\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.1082 - val_accuracy: 0.9760\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.1149 - val_accuracy: 0.9765\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0514 - accuracy: 0.9847 - val_loss: 0.1006 - val_accuracy: 0.9769\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.1146 - val_accuracy: 0.9761\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.1106 - val_accuracy: 0.9764\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0483 - accuracy: 0.9860 - val_loss: 0.1092 - val_accuracy: 0.9772\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0494 - accuracy: 0.9858 - val_loss: 0.1100 - val_accuracy: 0.9776\n"
          ]
        }
      ],
      "source": [
        "# - Using the validation database\n",
        "# - On the 'history' variable we have the history of executions (error and ac)\n",
        "neural_network.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "\n",
        "history = neural_network.fit(X_train, y_train, epochs = 100,\n",
        "                       validation_data = (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9fGEVF-rSZic",
        "outputId": "11936e49-69e3-4206-979f-9f9c9d6c9b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f18cce430d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualizing errors and accuracy\n",
        "print(history.history.keys())\n",
        "\n",
        "# Network error, blue\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "# Network performance\n",
        "plt.plot(history.history['val_accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qHsWUfPSZid",
        "outputId": "cf9df698-9152-4359-ad1a-88f58e625256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8553983e-18, 3.1340006e-09, 1.0378201e-08, ..., 1.0000000e+00,\n",
              "        1.6937921e-15, 3.4591230e-10],\n",
              "       [3.4774003e-14, 8.0312390e-13, 1.0000000e+00, ..., 1.7102331e-13,\n",
              "        2.1524870e-16, 2.8707696e-16],\n",
              "       [1.2672945e-24, 1.0000000e+00, 1.3760570e-10, ..., 5.1481541e-10,\n",
              "        6.2624455e-17, 1.9898045e-18],\n",
              "       ...,\n",
              "       [1.5719781e-16, 1.6038539e-09, 6.1659032e-11, ..., 1.1716272e-08,\n",
              "        4.1118020e-13, 1.9888168e-08],\n",
              "       [1.7880123e-22, 2.6458132e-19, 2.4371143e-17, ..., 1.3662631e-17,\n",
              "        1.0896093e-15, 7.7153796e-17],\n",
              "       [8.2032490e-15, 9.4195348e-24, 2.5490554e-14, ..., 2.1374105e-28,\n",
              "        2.4382941e-18, 2.0414476e-19]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# Getting the predictions\n",
        "predictions = neural_network.predict(X_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAOBs69dSZid",
        "outputId": "9970f308-eb08-4adb-dbb0-0f05c7312ec5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 968,    1,    1,    1,    1,    1,    1,    3,    2,    1],\n",
              "       [   0, 1123,    4,    0,    0,    1,    2,    1,    4,    0],\n",
              "       [   1,    1, 1015,    1,    1,    0,    2,    6,    4,    1],\n",
              "       [   0,    0,    4,  990,    0,    4,    0,    4,    4,    4],\n",
              "       [   2,    1,    4,    0,  953,    0,    7,    0,    0,   15],\n",
              "       [   3,    0,    0,   10,    1,  866,    4,    1,    4,    3],\n",
              "       [   5,    3,    2,    0,    3,    5,  939,    0,    1,    0],\n",
              "       [   2,    5,   10,    2,    1,    0,    0,  999,    1,    8],\n",
              "       [   5,    2,    6,    4,    4,    7,    0,    5,  936,    5],\n",
              "       [   2,    4,    0,    4,    5,    1,    0,    5,    1,  987]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Confusion Matrix\n",
        "y_test_matrix = [np.argmax(t) for t in y_test]\n",
        "y_predictions_matrix = [np.argmax(t) for t in predictions]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_matrix, y_predictions_matrix)\n",
        "conf_matrix\n",
        "\n",
        "# GOOD PERFORMANCE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Testing the Model***"
      ],
      "metadata": {
        "id": "Kt3FWyfdj7u8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5DonGXTSZid",
        "outputId": "b290c886-bb23-493a-becb-b6dae3828110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Testing with a new data, formating the array to a matrix\n",
        "y_train[20]\n",
        "\n",
        "# Number 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j60MTBKSZie",
        "outputId": "1d45ce9f-938c-4eeb-d704-3b72647f75ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Passing the same position for the model to predict\n",
        "new_data = X_train[20]\n",
        "\n",
        "# From matrix to vector\n",
        "new_data = np.expand_dims(new_data, axis = 0) # Expande o tamanho do array\n",
        "\n",
        "# Prediction\n",
        "prediction = neural_network.predict(new_data)\n",
        "\n",
        "# Highest value\n",
        "prediction = [np.argmax(prediction) for t in prediction]\n",
        "prediction\n",
        "\n",
        "# PREDITION CORRECT"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "343f115f40a8053497179efaaabbcede37074ddc2d78a1917bbcb3055274ce2f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Deep_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}